Implementation:

For our implementation of the paper, "UNSUPERVISED REPRESENTATION LEARNING BY PREDICTING IMAGE ROTATIONS" (Gidaris et al.), we used PyTorch to train a ResNet-18 CNN architecture on the task of predicting CIFAR-10 image rotations. The data was loaded in through DataLoaders and a custom Dataset implementation, and for each iteration produces four rotations of the next CIFAR-10 image from the dataset, along with 4 labels. These 4 are fed consecutively to the learning algorithm during training within a batch size of 512, for 100 epochs. For optimizer and criteria we used SGD with hyperparamaters as outlined in config.yaml, along with cross-entropy loss. 

Results:

Due to problems with setting up cloud compute on Amazon AWS, we were forced to use local resources for training. As a result, we were only able to complete around 20 epochs before running out of time. We started with a total loss of 116.08, validation loss of 22.6, and accuracy of 17.6%. At the end of epoch 21 we reached 98 total loss, 19.8 validation loss, and 23.3% accuracy. Though we did not achieve satisfactory results, our code correctly implements the paper and would demonstrate better results given more time and access to compute.